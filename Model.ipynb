{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yz/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/yz/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from loadDatas import *\n",
    "import collections\n",
    "from optim import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    '''\n",
    "    决策树的节点信息\n",
    "    '''\n",
    "    def __init__(self,name = None,spiltValue = None,parentNode = None,feat = 'InNode'):\n",
    "        '''\n",
    "        -self.name:节点的名字\n",
    "        -self.spiltValue:节点的边界数值\n",
    "        -self.parentNode:节点的父节点\n",
    "        -self.leftNode:节点的左子节点\n",
    "        -self.rightNode:节点的右子节点\n",
    "        -self.eva:当前节点的评价值\n",
    "        -self.feat:当前节点的属性，'InNode':内部节点，'LeafNode':叶节点\n",
    "        -self.index:当前节点的预测值\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.spiltValue = spiltValue\n",
    "        self.parentNode = parentNode\n",
    "        self.leftNode = None\n",
    "        self.rightNode = None\n",
    "        self.eva = 0\n",
    "        self.feat = feat\n",
    "        self.index = None\n",
    "        self.values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    '''\n",
    "    决策树\n",
    "    '''\n",
    "    def __init__(self,category = 'ID3',preCut = False,numBorder = 5,EBorder = 0.05):\n",
    "        '''\n",
    "        -self.tree:决策树\n",
    "        -self.category:决策树的模型类别,'ID3','C4.5','CART'\n",
    "        -self.preCut:是否进行预剪枝\n",
    "        -self.numBorder:预剪枝的数目边界，默认5\n",
    "        -self.EBorder:预剪枝的信息熵边界，默认0.05\n",
    "        '''\n",
    "        self.tree = TreeNode()\n",
    "        self.category = category\n",
    "        self.preCut = preCut\n",
    "        self.numBorder = numBorder\n",
    "        self.EBorder = EBorder\n",
    "    \n",
    "    def bulidTree(self,x,y,atts,parentNode = None):\n",
    "        '''\n",
    "        模型训练,\n",
    "        Inputs:\n",
    "        -x:训练数据\n",
    "        -y:训练标签\n",
    "        -atts:每一个属性上的分类\n",
    "        -parentNode:父节点\n",
    "        \n",
    "        Outputs:\n",
    "        -treeNode:一个节点\n",
    "        '''\n",
    "        #创建子节点\n",
    "        treeNode = TreeNode()\n",
    "\n",
    "        #预剪枝\n",
    "        if(self.preCut):\n",
    "            #如果数据小于数据边界\n",
    "            if(y.shape[0] <= self.numBorder):\n",
    "                treeNode.spiltValue = None\n",
    "                treeNode.parentNode = parentNode\n",
    "                treeNode.feat = 'LeafNode'\n",
    "                treeNode.index = max(collections.Counter(y),key = collections.Counter(y).get)\n",
    "                return treeNode\n",
    "        #如果该节点无训练数据，返回\n",
    "        if(y.all() == None):\n",
    "            return None\n",
    "        #将第一个节点与模型的self.tree链接\n",
    "        if parentNode == None:\n",
    "            parentNode = self.tree\n",
    "            self.tree.leftNode = treeNode\n",
    "            self.tree.rightNode = treeNode\n",
    "        #如果节点的标签都是一样的，即都为一个分类\n",
    "        if (list(set(y)) == 1 ):\n",
    "            treeNode.spiltValue = None\n",
    "            treeNode.parentNode = parentNode\n",
    "            treeNode.feat = 'LeafNode'\n",
    "            treeNode.index = max(collections.Counter(y),key = collections.Counter(y).get)\n",
    "            return treeNode\n",
    "        #得到当前节点最好的分割属性和分割值\n",
    "        bestName,bestValue,bestEva = self.chooseBestNode(x,y,atts)\n",
    "        #预剪枝\n",
    "        if(self.preCut):\n",
    "            #如果评价值小于评价值边界\n",
    "            if(bestEva < self.EBorder):\n",
    "                treeNode.spiltValue = None\n",
    "                treeNode.parentNode = parentNode\n",
    "                treeNode.feat = 'LeafNode'\n",
    "                treeNode.index = max(collections.Counter(y),key = collections.Counter(y).get)\n",
    "                return treeNode\n",
    "        treeNode.name = bestName\n",
    "        treeNode.spiltValue = bestValue\n",
    "        treeNode.eva = bestEva\n",
    "        treeNode.parentNode = parentNode\n",
    "        treeNode.index = max(collections.Counter(y),key = collections.Counter(y).get)\n",
    "        #如果分割节点失败，将该节点设置为叶节点\n",
    "        if(bestValue == None):\n",
    "            treeNode.feat = 'LeafNode'\n",
    "            return treeNode\n",
    "        #分割数据\n",
    "        X_left,Y_left,X_right,Y_right = self.spiltDatas(x,y,bestName,bestValue)\n",
    "        #添加该节点的左右节点\n",
    "        treeNode.leftNode = self.bulidTree(X_left,Y_left,atts,treeNode)\n",
    "        treeNode.rightNode = self.bulidTree(X_right,Y_right,atts,treeNode)\n",
    "        return treeNode\n",
    "    \n",
    "    def chooseBestNode(self,x,y,atts):\n",
    "        '''\n",
    "        选择当前属性的最好节点\n",
    "        Inputs:\n",
    "        -x:当前节点的训练数据\n",
    "        -y:当前节点的训练标签\n",
    "        -atts:当前节点可供选择的所有属性 list\n",
    "        \n",
    "        Outputs:\n",
    "        -bestName:最好的节点列数\n",
    "        -bestValue:最好的划分值\n",
    "        -bestEva:得到的最好的评价\n",
    "        '''\n",
    "        bestName = None\n",
    "        bestValue = None\n",
    "        bestEva = -np.inf\n",
    "        for col,att in enumerate(atts):\n",
    "            for value in att:\n",
    "                E = self.computeEva(x,y,col,value)\n",
    "                if E> bestEva:\n",
    "                    bestEva = E\n",
    "                    bestName = col\n",
    "                    bestValue = value\n",
    "        return bestName,bestValue,bestEva\n",
    "    \n",
    "    def computeEva(self,x,y,col,value):\n",
    "        '''\n",
    "        计算评价值\n",
    "        -x:该节点的数据\n",
    "        -y:该节点的标签\n",
    "        -col:属性的列数\n",
    "        -value:要划分的值\n",
    "        '''\n",
    "        nums = x.shape[0]\n",
    "        E = self.computEntropy(y)\n",
    "        X_left,Y_left,X_right,Y_right = self.spiltDatas(x,y,col,value)\n",
    "        num1 = len(X_left)\n",
    "        p1 = num1/nums\n",
    "        E1 = self.computEntropy(Y_left)\n",
    "        num2 = len(X_right)\n",
    "        p2 = num2/nums\n",
    "        E2 = self.computEntropy(Y_right)\n",
    "        \n",
    "        if self.category == 'ID3':\n",
    "            result = E - (p1 * E1 + p2 * E2)\n",
    "        elif self.category == 'C4.5':\n",
    "            result = E - (p1 * E1 + p2 * E2)\n",
    "            result /= -(p1 * np.log(p1) + p2 * np.log(p2))\n",
    "        elif self.category == 'CART':\n",
    "            result = -(p1 * E1 + p2 * E2)\n",
    "        return result\n",
    "            \n",
    "    def computEntropy(self,y):\n",
    "        '''\n",
    "        计算信息熵\n",
    "        '''\n",
    "        num = y.shape[0]\n",
    "        num1 = np.sum(y)\n",
    "        num2 = num - num1\n",
    "        p1 = num1/num\n",
    "        p2 = num2/num\n",
    "        if self.category == ('ID3' or 'C4.5'):\n",
    "            E = -(p1 * np.log(p1) + p2 * np.log(p2))\n",
    "        elif self.category == 'CART':\n",
    "            E = 1 - (p1 **2 + p2 **2)\n",
    "        return E\n",
    "    \n",
    "    def spiltDatas(self,x,y,col,value):\n",
    "        '''\n",
    "        将数据分割\n",
    "        Inputs:\n",
    "        -x:待分割数据\n",
    "        -y:带分割数据\n",
    "        -col：要分割的属性位置\n",
    "        -value:分割边界\n",
    "        '''\n",
    "        X_left =x[x[:,col] <= value]\n",
    "        Y_left = y[x[:,col] <= value]\n",
    "        X_right =x[x[:,col] > value]\n",
    "        Y_right = y[x[:,col] > value]\n",
    "        return X_left,Y_left,X_right,Y_right\n",
    "    \n",
    "    def predict(self,X,Y = None):\n",
    "        pre = []\n",
    "        for i,x in enumerate(X):\n",
    "            if Y.all()!= None:\n",
    "                y = Y[i]\n",
    "            t = self.tree.leftNode\n",
    "            while(t.feat != 'LeafNode'):\n",
    "                t.values.append(y)\n",
    "                name = t.name\n",
    "                value = t.spiltValue\n",
    "                if(value == None):\n",
    "                    t = t.parentNode\n",
    "                    break\n",
    "                if(x[name] <= value):\n",
    "                    t = t.leftNode\n",
    "                else:\n",
    "                    t = t.rightNode\n",
    "            pre.append(t.index)\n",
    "        pre = np.array(pre).reshape((len(pre),))\n",
    "        if(y.all() == None):\n",
    "            return pre\n",
    "        score = np.sum(pre == Y)\n",
    "        score /= Y.shape[0]\n",
    "        return pre,score\n",
    "    \n",
    "    def afterCut(self,X_test,Y_test,tree = None):\n",
    "        if(tree == None):\n",
    "            tree = self.tree.leftNode\n",
    "            self.predict(X_test,Y_test)\n",
    "        if(tree.feat == 'LeafNode'):\n",
    "            return\n",
    "        self.afterCut(X_test,Y_test,tree.leftNode)\n",
    "        self.afterCut(X_test,Y_test,tree.rightNode)\n",
    "        #判断是否需要剪枝\n",
    "        acc = np.sum(tree.values == tree.index)/len(tree.values)\n",
    "        acc1 = (np.sum(tree.leftNode.values == tree.leftNode.index) + \n",
    "               np.sum(tree.rightNode.values == tree.rightNode.index))/len(tree.values)\n",
    "        if(acc >= acc1):\n",
    "            tree.leftNode = None\n",
    "            tree.rightNode = None\n",
    "            tree.feat = 'LeafNode'\n",
    "        if(len(tree.values) <= self.numBorder):\n",
    "            tree.leftNode = None\n",
    "            tree.rightNode = None\n",
    "            tree.feat = 'LeafNode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    '''\n",
    "    线性分类器\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        -self.w : 初始化权重，(D,H)\n",
    "        -self.b: 初始化bias,(H,)\n",
    "        '''\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "    def train(self,X,y,out_dims,\n",
    "              lr = 1e-5,reg = 1e-2,\n",
    "              batch_size = 32,epoch = 5,weight_scale = 1e-5,printFreq = 20,\n",
    "              grad_function = sgd,activation_function = 'relu'):\n",
    "        '''\n",
    "        Inputs:\n",
    "        -X:训练数据 (N,D)\n",
    "        -y:数据标签,(H,)\n",
    "        -lr:学习率\n",
    "        -reg:正则化参数\n",
    "        -batch_size:每次迭代的数目\n",
    "        -epoch:对全部数据迭代的次数\n",
    "        -weight_scale:对Ｗ初始化的权重\n",
    "        -printFreq:经过几个batch输出一次loss和accuracy\n",
    "        \n",
    "        Outputs:\n",
    "        -loss_history:list,所有的loss\n",
    "        '''\n",
    "        N,D = X.shape\n",
    "        H = out_dims\n",
    "        self.W = weight_scale * np.random.randn(D,H)\n",
    "        self.b = np.zeros((H,))\n",
    "        loss_history  = []\n",
    "        acc_history = []\n",
    "        config = {'lr':lr}\n",
    "        \n",
    "        ## 设置激活函数\n",
    "        if activation_function == 'relu':\n",
    "            self.activation_forward = relu_forward\n",
    "            self.activation_backward = relu_backward\n",
    "        if activation_function == 'sigmoid':\n",
    "            self.activation_forward = sigmoid_forward\n",
    "            self.activation_backward = sigmoid_backward\n",
    "        if activation_function == 'tanh':\n",
    "            self.activation_forward = tanh_forward\n",
    "            self.activation_backward = tanh_backward\n",
    "        \n",
    "        iter_nums = int(N/batch_size) * epoch\n",
    "        for i in range(iter_nums):\n",
    "            #随机获得batch_size个数据\n",
    "            index = np.random.randint(0,N,batch_size)\n",
    "            xx = X[index]\n",
    "            yy = y[index]\n",
    "            #正向传播\n",
    "            z = xx.dot(self.W) + self.b\n",
    "            #激活函数\n",
    "            out,cache = self.activation_forward(z)\n",
    "            #得到准确率\n",
    "            acc = np.sum(out.argmax(axis = 1) == yy)/yy.shape[0]\n",
    "            acc_history.append(acc)\n",
    "            #得到loss\n",
    "            loss,dout = self.loss(out,yy)\n",
    "            loss_history.append(loss)\n",
    "            #激活函数反向传播\n",
    "            dx = self.activation_backward(dout,cache)\n",
    "            #得到梯度\n",
    "            dw = xx.T.dot(dx)\n",
    "            db = dout.sum(axis = 0)\n",
    "            #梯度下降\n",
    "            self.W = grad_function(self.W,dw,config)\n",
    "            self.b = grad_function(self.b,db,config)\n",
    "            \n",
    "            if (i+1) % printFreq == 0:\n",
    "                print(\"epoch \",int(i/(iter_nums/epoch)),'|',epoch,'\\t','acc = ',acc,'\\tloss = ',loss)\n",
    "        return loss_history,acc_history\n",
    "            \n",
    "    def loss(self,out,y):\n",
    "        '''\n",
    "        依靠具体的模型决定\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def predict(self,X,y = None):\n",
    "        z = X.dot(self.W) + self.b\n",
    "        out,_ = self.activation_forward(z)\n",
    "        out = out.argmax(axis = 1)\n",
    "        if y.all() == None:\n",
    "            return out,_\n",
    "        acc = np.sum(out == y)/y.shape[0]\n",
    "        return out,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(Linear):\n",
    "    def loss(self,out,y):\n",
    "        loss,dx = svm_loss(out,y)\n",
    "        return loss,dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(Linear):\n",
    "    def loss(self,out,y):\n",
    "        loss,dx = softmax_loss(out,y)\n",
    "        return loss,dx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
